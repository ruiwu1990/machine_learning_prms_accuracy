17/03/26 20:37:51 INFO spark.SparkContext: Running Spark version 2.0.1
17/03/26 20:37:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/26 20:37:52 INFO spark.SecurityManager: Changing view acls to: root
17/03/26 20:37:52 INFO spark.SecurityManager: Changing modify acls to: root
17/03/26 20:37:52 INFO spark.SecurityManager: Changing view acls groups to: 
17/03/26 20:37:52 INFO spark.SecurityManager: Changing modify acls groups to: 
17/03/26 20:37:52 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
17/03/26 20:37:52 INFO util.Utils: Successfully started service 'sparkDriver' on port 39203.
17/03/26 20:37:52 INFO spark.SparkEnv: Registering MapOutputTracker
17/03/26 20:37:52 INFO spark.SparkEnv: Registering BlockManagerMaster
17/03/26 20:37:52 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-0000fbbc-af34-4108-9f9f-2e241580e872
17/03/26 20:37:52 INFO memory.MemoryStore: MemoryStore started with capacity 413.9 MB
17/03/26 20:37:52 INFO spark.SparkEnv: Registering OutputCommitCoordinator
17/03/26 20:37:53 INFO util.log: Logging initialized @3396ms
17/03/26 20:37:53 INFO server.Server: jetty-9.2.z-SNAPSHOT
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@32e463cf{/jobs,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@f77c212{/jobs/json,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@e769db9{/jobs/job,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@23e0bd32{/jobs/job/json,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@328b489a{/stages,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3dd7b8b{/stages/json,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@397cb51c{/stages/stage,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1fd3962c{/stages/stage/json,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7774d2d4{/stages/pool,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f9dee92{/stages/pool/json,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@43956c28{/storage,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40f4e080{/storage/json,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@11476838{/storage/rdd,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@615eedfc{/storage/rdd/json,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9c239d3{/environment,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6e55288b{/environment/json,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44f98bd1{/executors,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@525eafbf{/executors/json,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4a4a0886{/executors/threadDump,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d9c6034{/executors/threadDump/json,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@533d555{/static,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@22b7b11b{/,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@38a383f3{/api,null,AVAILABLE}
17/03/26 20:37:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5650d913{/stages/stage/kill,null,AVAILABLE}
17/03/26 20:37:53 INFO server.ServerConnector: Started ServerConnector@1bb4504c{HTTP/1.1}{0.0.0.0:4040}
17/03/26 20:37:53 INFO server.Server: Started @3634ms
17/03/26 20:37:53 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
17/03/26 20:37:53 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.17.0.4:4040
17/03/26 20:37:53 INFO spark.SparkContext: Added file file:/regtool/ml_moduel/random_forest_regression.py at file:/regtool/ml_moduel/random_forest_regression.py with timestamp 1490560673689
17/03/26 20:37:53 INFO util.Utils: Copying /regtool/ml_moduel/random_forest_regression.py to /tmp/spark-ac333ad8-13b2-4152-9034-97a87dd4b7f8/userFiles-7bdb1517-cb12-4afb-9afa-a1a86f847aa3/random_forest_regression.py
17/03/26 20:37:53 INFO executor.Executor: Starting executor ID driver on host localhost
17/03/26 20:37:53 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37608.
17/03/26 20:37:53 INFO netty.NettyBlockTransferService: Server created on 172.17.0.4:37608
17/03/26 20:37:53 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.17.0.4, 37608)
17/03/26 20:37:53 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.17.0.4:37608 with 413.9 MB RAM, BlockManagerId(driver, 172.17.0.4, 37608)
17/03/26 20:37:53 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.17.0.4, 37608)
17/03/26 20:37:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4f97c9aa{/metrics/json,null,AVAILABLE}
17/03/26 20:37:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@c1b6c63{/SQL,null,AVAILABLE}
17/03/26 20:37:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@13b2db18{/SQL/json,null,AVAILABLE}
17/03/26 20:37:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@105760d6{/SQL/execution,null,AVAILABLE}
17/03/26 20:37:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@63293d3c{/SQL/execution/json,null,AVAILABLE}
17/03/26 20:37:54 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2f67750c{/static/sql,null,AVAILABLE}
17/03/26 20:37:54 INFO internal.SharedState: Warehouse path is '/regtool/spark-warehouse'.
17/03/26 20:37:55 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 232.0 KB, free 413.7 MB)
17/03/26 20:37:55 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.6 KB, free 413.7 MB)
17/03/26 20:37:55 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.17.0.4:37608 (size: 22.6 KB, free: 413.9 MB)
17/03/26 20:37:55 INFO spark.SparkContext: Created broadcast 0 from textFile at MLUtils.scala:99
17/03/26 20:37:55 INFO mapred.FileInputFormat: Total input paths to process : 1
17/03/26 20:37:55 INFO spark.SparkContext: Starting job: reduce at MLUtils.scala:92
17/03/26 20:37:55 INFO scheduler.DAGScheduler: Got job 0 (reduce at MLUtils.scala:92) with 1 output partitions
17/03/26 20:37:55 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
17/03/26 20:37:55 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/03/26 20:37:55 INFO scheduler.DAGScheduler: Missing parents: List()
17/03/26 20:37:55 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
17/03/26 20:37:55 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 413.7 MB)
17/03/26 20:37:55 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 413.7 MB)
17/03/26 20:37:55 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.17.0.4:37608 (size: 2.2 KB, free: 413.9 MB)
17/03/26 20:37:55 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1012
17/03/26 20:37:55 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90)
17/03/26 20:37:55 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/03/26 20:37:55 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5484 bytes)
17/03/26 20:37:55 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/26 20:37:55 INFO executor.Executor: Fetching file:/regtool/ml_moduel/random_forest_regression.py with timestamp 1490560673689
17/03/26 20:37:55 INFO util.Utils: /regtool/ml_moduel/random_forest_regression.py has been previously copied to /tmp/spark-ac333ad8-13b2-4152-9034-97a87dd4b7f8/userFiles-7bdb1517-cb12-4afb-9afa-a1a86f847aa3/random_forest_regression.py
17/03/26 20:37:56 INFO rdd.HadoopRDD: Input split: file:/regtool/static/data/delta_error.libsvm:0+174636
17/03/26 20:37:56 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/03/26 20:37:56 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/03/26 20:37:56 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/03/26 20:37:56 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/03/26 20:37:56 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/03/26 20:37:56 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 1192 bytes result sent to driver
17/03/26 20:37:56 INFO scheduler.DAGScheduler: ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.604 s
17/03/26 20:37:56 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 590 ms on localhost (1/1)
17/03/26 20:37:56 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/26 20:37:56 INFO scheduler.DAGScheduler: Job 0 finished: reduce at MLUtils.scala:92, took 0.865653 s
17/03/26 20:37:58 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 172.17.0.4:37608 in memory (size: 2.2 KB, free: 413.9 MB)
17/03/26 20:37:58 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 172.17.0.4:37608 in memory (size: 22.6 KB, free: 413.9 MB)
17/03/26 20:37:59 INFO datasources.FileSourceStrategy: Pruning directories with: 
17/03/26 20:37:59 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
17/03/26 20:37:59 INFO datasources.FileSourceStrategy: Pruned Data Schema: struct<features: vector>
17/03/26 20:37:59 INFO datasources.FileSourceStrategy: Pushed Filters: 
17/03/26 20:37:59 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 264.4 KB, free 413.7 MB)
17/03/26 20:37:59 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.1 KB, free 413.6 MB)
17/03/26 20:37:59 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.17.0.4:37608 (size: 23.1 KB, free: 413.9 MB)
17/03/26 20:37:59 INFO spark.SparkContext: Created broadcast 2 from broadcast at LibSVMRelation.scala:161
17/03/26 20:37:59 INFO datasources.FileSourceStrategy: Planning scan with bin packing, max size: 4368940 bytes, open cost is considered as scanning 4194304 bytes.
17/03/26 20:37:59 INFO codegen.CodeGenerator: Code generated in 354.76675 ms
17/03/26 20:37:59 INFO spark.SparkContext: Starting job: take at VectorIndexer.scala:118
17/03/26 20:37:59 INFO scheduler.DAGScheduler: Got job 1 (take at VectorIndexer.scala:118) with 1 output partitions
17/03/26 20:37:59 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (take at VectorIndexer.scala:118)
17/03/26 20:37:59 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/03/26 20:37:59 INFO scheduler.DAGScheduler: Missing parents: List()
17/03/26 20:37:59 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at take at VectorIndexer.scala:118), which has no missing parents
17/03/26 20:38:00 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.9 KB, free 413.6 MB)
17/03/26 20:38:00 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.9 KB, free 413.6 MB)
17/03/26 20:38:00 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.17.0.4:37608 (size: 3.9 KB, free: 413.9 MB)
17/03/26 20:38:00 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:00 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at take at VectorIndexer.scala:118)
17/03/26 20:38:00 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/26 20:38:00 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5936 bytes)
17/03/26 20:38:00 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)
17/03/26 20:38:00 INFO datasources.FileScanRDD: Reading File path: file:///regtool/static/data/delta_error.libsvm, range: 0-174636, partition values: [empty row]
17/03/26 20:38:00 INFO codegen.CodeGenerator: Code generated in 69.66432 ms
17/03/26 20:38:00 INFO codegen.CodeGenerator: Code generated in 34.212822 ms
17/03/26 20:38:00 INFO codegen.CodeGenerator: Code generated in 95.250502 ms
17/03/26 20:38:00 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 1485 bytes result sent to driver
17/03/26 20:38:00 INFO scheduler.DAGScheduler: ResultStage 1 (take at VectorIndexer.scala:118) finished in 0.374 s
17/03/26 20:38:00 INFO scheduler.DAGScheduler: Job 1 finished: take at VectorIndexer.scala:118, took 0.441644 s
17/03/26 20:38:00 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 382 ms on localhost (1/1)
17/03/26 20:38:00 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/26 20:38:00 INFO codegen.CodeGenerator: Code generated in 26.23844 ms
17/03/26 20:38:00 INFO datasources.FileSourceStrategy: Pruning directories with: 
17/03/26 20:38:00 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
17/03/26 20:38:00 INFO datasources.FileSourceStrategy: Pruned Data Schema: struct<features: vector>
17/03/26 20:38:00 INFO datasources.FileSourceStrategy: Pushed Filters: 
17/03/26 20:38:00 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 264.4 KB, free 413.4 MB)
17/03/26 20:38:00 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.1 KB, free 413.4 MB)
17/03/26 20:38:00 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.17.0.4:37608 (size: 23.1 KB, free: 413.9 MB)
17/03/26 20:38:00 INFO spark.SparkContext: Created broadcast 4 from broadcast at LibSVMRelation.scala:161
17/03/26 20:38:00 INFO datasources.FileSourceStrategy: Planning scan with bin packing, max size: 4368940 bytes, open cost is considered as scanning 4194304 bytes.
17/03/26 20:38:00 INFO spark.SparkContext: Starting job: reduce at VectorIndexer.scala:127
17/03/26 20:38:00 INFO scheduler.DAGScheduler: Got job 2 (reduce at VectorIndexer.scala:127) with 1 output partitions
17/03/26 20:38:00 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (reduce at VectorIndexer.scala:127)
17/03/26 20:38:00 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/03/26 20:38:00 INFO scheduler.DAGScheduler: Missing parents: List()
17/03/26 20:38:00 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at mapPartitions at VectorIndexer.scala:123), which has no missing parents
17/03/26 20:38:00 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KB, free 413.3 MB)
17/03/26 20:38:00 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.3 KB, free 413.3 MB)
17/03/26 20:38:00 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.17.0.4:37608 (size: 5.3 KB, free: 413.9 MB)
17/03/26 20:38:00 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:00 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at mapPartitions at VectorIndexer.scala:123)
17/03/26 20:38:00 INFO scheduler.TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/03/26 20:38:00 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5991 bytes)
17/03/26 20:38:00 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 2)
17/03/26 20:38:00 INFO datasources.FileScanRDD: Reading File path: file:///regtool/static/data/delta_error.libsvm, range: 0-174636, partition values: [empty row]
17/03/26 20:38:01 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 2). 6850 bytes result sent to driver
17/03/26 20:38:01 INFO scheduler.DAGScheduler: ResultStage 2 (reduce at VectorIndexer.scala:127) finished in 0.466 s
17/03/26 20:38:01 INFO scheduler.DAGScheduler: Job 2 finished: reduce at VectorIndexer.scala:127, took 0.534062 s
17/03/26 20:38:01 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 471 ms on localhost (1/1)
17/03/26 20:38:01 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/26 20:38:01 INFO spark.ContextCleaner: Cleaned accumulator 91
17/03/26 20:38:01 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 172.17.0.4:37608 in memory (size: 5.3 KB, free: 413.9 MB)
17/03/26 20:38:01 INFO spark.ContextCleaner: Cleaned accumulator 92
17/03/26 20:38:01 INFO datasources.FileSourceStrategy: Pruning directories with: 
17/03/26 20:38:01 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
17/03/26 20:38:01 INFO datasources.FileSourceStrategy: Pruned Data Schema: struct<label: double, features: vector>
17/03/26 20:38:01 INFO datasources.FileSourceStrategy: Pushed Filters: 
17/03/26 20:38:01 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 264.4 KB, free 413.1 MB)
17/03/26 20:38:01 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.1 KB, free 413.1 MB)
17/03/26 20:38:01 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.17.0.4:37608 (size: 23.1 KB, free: 413.9 MB)
17/03/26 20:38:01 INFO spark.SparkContext: Created broadcast 6 from broadcast at LibSVMRelation.scala:161
17/03/26 20:38:01 INFO datasources.FileSourceStrategy: Planning scan with bin packing, max size: 4368940 bytes, open cost is considered as scanning 4194304 bytes.
17/03/26 20:38:01 INFO codegen.CodeGenerator: Code generated in 133.795858 ms
17/03/26 20:38:02 INFO util.Instrumentation: RandomForestRegressor-RandomForestRegressor_46d39ead464f96cb904c-550524158-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
17/03/26 20:38:02 INFO util.Instrumentation: RandomForestRegressor-RandomForestRegressor_46d39ead464f96cb904c-550524158-1: {"seed":-5851613654371098793,"subsamplingRate":1.0,"impurity":"variance","featuresCol":"indexedFeatures","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
17/03/26 20:38:02 INFO spark.SparkContext: Starting job: take at DecisionTreeMetadata.scala:112
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Got job 3 (take at DecisionTreeMetadata.scala:112) with 1 output partitions
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (take at DecisionTreeMetadata.scala:112)
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Missing parents: List()
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[21] at map at DecisionTreeMetadata.scala:112), which has no missing parents
17/03/26 20:38:02 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.9 KB, free 413.0 MB)
17/03/26 20:38:02 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.1 KB, free 413.0 MB)
17/03/26 20:38:02 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.17.0.4:37608 (size: 11.1 KB, free: 413.8 MB)
17/03/26 20:38:02 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[21] at map at DecisionTreeMetadata.scala:112)
17/03/26 20:38:02 INFO scheduler.TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/03/26 20:38:02 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5989 bytes)
17/03/26 20:38:02 INFO executor.Executor: Running task 0.0 in stage 3.0 (TID 3)
17/03/26 20:38:02 INFO codegen.CodeGenerator: Code generated in 84.903278 ms
17/03/26 20:38:02 INFO codegen.CodeGenerator: Code generated in 39.853483 ms
17/03/26 20:38:02 INFO codegen.CodeGenerator: Code generated in 26.154958 ms
17/03/26 20:38:02 INFO datasources.FileScanRDD: Reading File path: file:///regtool/static/data/delta_error.libsvm, range: 0-174636, partition values: [empty row]
17/03/26 20:38:02 INFO codegen.CodeGenerator: Code generated in 37.678116 ms
17/03/26 20:38:02 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 172.17.0.4:37608 in memory (size: 23.1 KB, free: 413.9 MB)
17/03/26 20:38:02 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 172.17.0.4:37608 in memory (size: 3.9 KB, free: 413.9 MB)
17/03/26 20:38:02 INFO spark.ContextCleaner: Cleaned accumulator 46
17/03/26 20:38:02 INFO spark.ContextCleaner: Cleaned accumulator 45
17/03/26 20:38:02 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 172.17.0.4:37608 in memory (size: 23.1 KB, free: 413.9 MB)
17/03/26 20:38:02 INFO executor.Executor: Finished task 0.0 in stage 3.0 (TID 3). 1705 bytes result sent to driver
17/03/26 20:38:02 INFO scheduler.DAGScheduler: ResultStage 3 (take at DecisionTreeMetadata.scala:112) finished in 0.525 s
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Job 3 finished: take at DecisionTreeMetadata.scala:112, took 0.554893 s
17/03/26 20:38:02 INFO spark.SparkContext: Starting job: count at DecisionTreeMetadata.scala:116
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Got job 4 (count at DecisionTreeMetadata.scala:116) with 1 output partitions
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (count at DecisionTreeMetadata.scala:116)
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Missing parents: List()
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at retag at RandomForest.scala:103), which has no missing parents
17/03/26 20:38:02 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 25.5 KB, free 413.6 MB)
17/03/26 20:38:02 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 525 ms on localhost (1/1)
17/03/26 20:38:02 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/26 20:38:02 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 10.9 KB, free 413.6 MB)
17/03/26 20:38:02 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.17.0.4:37608 (size: 10.9 KB, free: 413.9 MB)
17/03/26 20:38:02 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at retag at RandomForest.scala:103)
17/03/26 20:38:02 INFO scheduler.TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/03/26 20:38:02 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5907 bytes)
17/03/26 20:38:02 INFO executor.Executor: Running task 0.0 in stage 4.0 (TID 4)
17/03/26 20:38:02 INFO datasources.FileScanRDD: Reading File path: file:///regtool/static/data/delta_error.libsvm, range: 0-174636, partition values: [empty row]
17/03/26 20:38:02 INFO executor.Executor: Finished task 0.0 in stage 4.0 (TID 4). 1843 bytes result sent to driver
17/03/26 20:38:02 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 243 ms on localhost (1/1)
17/03/26 20:38:02 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/26 20:38:02 INFO scheduler.DAGScheduler: ResultStage 4 (count at DecisionTreeMetadata.scala:116) finished in 0.249 s
17/03/26 20:38:02 INFO scheduler.DAGScheduler: Job 4 finished: count at DecisionTreeMetadata.scala:116, took 0.275566 s
17/03/26 20:38:02 INFO util.Instrumentation: RandomForestRegressor-RandomForestRegressor_46d39ead464f96cb904c-550524158-1: {"numFeatures":7}
17/03/26 20:38:02 INFO util.Instrumentation: RandomForestRegressor-RandomForestRegressor_46d39ead464f96cb904c-550524158-1: {"numClasses":0}
17/03/26 20:38:03 INFO spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:894
17/03/26 20:38:03 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 172.17.0.4:37608 in memory (size: 10.9 KB, free: 413.9 MB)
17/03/26 20:38:03 INFO scheduler.DAGScheduler: Registering RDD 23 (flatMap at RandomForest.scala:887)
17/03/26 20:38:03 INFO scheduler.DAGScheduler: Got job 5 (collectAsMap at RandomForest.scala:894) with 1 output partitions
17/03/26 20:38:03 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (collectAsMap at RandomForest.scala:894)
17/03/26 20:38:03 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/03/26 20:38:03 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/03/26 20:38:03 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at flatMap at RandomForest.scala:887), which has no missing parents
17/03/26 20:38:03 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 28.7 KB, free 413.6 MB)
17/03/26 20:38:03 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.5 KB, free 413.6 MB)
17/03/26 20:38:03 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.17.0.4:37608 (size: 12.5 KB, free: 413.9 MB)
17/03/26 20:38:03 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:03 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at flatMap at RandomForest.scala:887)
17/03/26 20:38:03 INFO scheduler.TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/03/26 20:38:03 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 6095 bytes)
17/03/26 20:38:03 INFO executor.Executor: Running task 0.0 in stage 5.0 (TID 5)
17/03/26 20:38:03 INFO datasources.FileScanRDD: Reading File path: file:///regtool/static/data/delta_error.libsvm, range: 0-174636, partition values: [empty row]
17/03/26 20:38:03 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 172.17.0.4:37608 in memory (size: 11.1 KB, free: 413.9 MB)
17/03/26 20:38:04 INFO executor.Executor: Finished task 0.0 in stage 5.0 (TID 5). 2129 bytes result sent to driver
17/03/26 20:38:04 INFO scheduler.DAGScheduler: ShuffleMapStage 5 (flatMap at RandomForest.scala:887) finished in 1.788 s
17/03/26 20:38:04 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/03/26 20:38:04 INFO scheduler.DAGScheduler: running: Set()
17/03/26 20:38:04 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 6)
17/03/26 20:38:04 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1788 ms on localhost (1/1)
17/03/26 20:38:04 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/26 20:38:04 INFO scheduler.DAGScheduler: failed: Set()
17/03/26 20:38:04 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[25] at map at RandomForest.scala:889), which has no missing parents
17/03/26 20:38:04 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 31.2 KB, free 413.6 MB)
17/03/26 20:38:04 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.7 KB, free 413.6 MB)
17/03/26 20:38:04 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.17.0.4:37608 (size: 13.7 KB, free: 413.9 MB)
17/03/26 20:38:04 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:04 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[25] at map at RandomForest.scala:889)
17/03/26 20:38:04 INFO scheduler.TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/03/26 20:38:04 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5249 bytes)
17/03/26 20:38:04 INFO executor.Executor: Running task 0.0 in stage 6.0 (TID 6)
17/03/26 20:38:04 INFO storage.ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/26 20:38:04 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
17/03/26 20:38:05 INFO executor.Executor: Finished task 0.0 in stage 6.0 (TID 6). 6007 bytes result sent to driver
17/03/26 20:38:05 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 344 ms on localhost (1/1)
17/03/26 20:38:05 INFO scheduler.DAGScheduler: ResultStage 6 (collectAsMap at RandomForest.scala:894) finished in 0.339 s
17/03/26 20:38:05 INFO scheduler.DAGScheduler: Job 5 finished: collectAsMap at RandomForest.scala:894, took 2.213500 s
17/03/26 20:38:05 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/26 20:38:05 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 2.2 KB, free 413.6 MB)
17/03/26 20:38:05 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 525.0 B, free 413.6 MB)
17/03/26 20:38:05 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.17.0.4:37608 (size: 525.0 B, free: 413.9 MB)
17/03/26 20:38:05 INFO spark.SparkContext: Created broadcast 11 from broadcast at RandomForest.scala:500
17/03/26 20:38:05 INFO spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:550
17/03/26 20:38:05 INFO scheduler.DAGScheduler: Registering RDD 28 (mapPartitions at RandomForest.scala:521)
17/03/26 20:38:05 INFO scheduler.DAGScheduler: Got job 6 (collectAsMap at RandomForest.scala:550) with 1 output partitions
17/03/26 20:38:05 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (collectAsMap at RandomForest.scala:550)
17/03/26 20:38:05 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/03/26 20:38:05 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 7)
17/03/26 20:38:05 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at mapPartitions at RandomForest.scala:521), which has no missing parents
17/03/26 20:38:05 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 35.6 KB, free 413.5 MB)
17/03/26 20:38:05 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.6 KB, free 413.5 MB)
17/03/26 20:38:05 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.17.0.4:37608 (size: 15.6 KB, free: 413.9 MB)
17/03/26 20:38:05 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at mapPartitions at RandomForest.scala:521)
17/03/26 20:38:05 INFO scheduler.TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/03/26 20:38:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5986 bytes)
17/03/26 20:38:05 INFO executor.Executor: Running task 0.0 in stage 7.0 (TID 7)
17/03/26 20:38:05 INFO datasources.FileScanRDD: Reading File path: file:///regtool/static/data/delta_error.libsvm, range: 0-174636, partition values: [empty row]
17/03/26 20:38:05 INFO memory.MemoryStore: Block rdd_27_0 stored as values in memory (estimated size 674.0 KB, free 412.8 MB)
17/03/26 20:38:05 INFO storage.BlockManagerInfo: Added rdd_27_0 in memory on 172.17.0.4:37608 (size: 674.0 KB, free: 413.2 MB)
17/03/26 20:38:05 INFO executor.Executor: Finished task 0.0 in stage 7.0 (TID 7). 2932 bytes result sent to driver
17/03/26 20:38:05 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 537 ms on localhost (1/1)
17/03/26 20:38:05 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/03/26 20:38:05 INFO scheduler.DAGScheduler: ShuffleMapStage 7 (mapPartitions at RandomForest.scala:521) finished in 0.530 s
17/03/26 20:38:05 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/03/26 20:38:05 INFO scheduler.DAGScheduler: running: Set()
17/03/26 20:38:05 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 8)
17/03/26 20:38:05 INFO scheduler.DAGScheduler: failed: Set()
17/03/26 20:38:05 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[30] at map at RandomForest.scala:540), which has no missing parents
17/03/26 20:38:05 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.4 KB, free 412.8 MB)
17/03/26 20:38:05 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.6 KB, free 412.8 MB)
17/03/26 20:38:05 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.17.0.4:37608 (size: 3.6 KB, free: 413.2 MB)
17/03/26 20:38:05 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[30] at map at RandomForest.scala:540)
17/03/26 20:38:05 INFO scheduler.TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/03/26 20:38:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, ANY, 5249 bytes)
17/03/26 20:38:05 INFO executor.Executor: Running task 0.0 in stage 8.0 (TID 8)
17/03/26 20:38:05 INFO storage.ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/26 20:38:05 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/26 20:38:06 INFO executor.Executor: Finished task 0.0 in stage 8.0 (TID 8). 5713 bytes result sent to driver
17/03/26 20:38:06 INFO scheduler.DAGScheduler: ResultStage 8 (collectAsMap at RandomForest.scala:550) finished in 0.120 s
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Job 6 finished: collectAsMap at RandomForest.scala:550, took 0.696587 s
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 4.8 KB, free 412.8 MB)
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 774.0 B, free 412.8 MB)
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 120 ms on localhost (1/1)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.17.0.4:37608 (size: 774.0 B, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.SparkContext: Created broadcast 14 from broadcast at RandomForest.scala:500
17/03/26 20:38:06 INFO spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:550
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Registering RDD 31 (mapPartitions at RandomForest.scala:521)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Got job 7 (collectAsMap at RandomForest.scala:550) with 1 output partitions
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (collectAsMap at RandomForest.scala:550)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 9)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[31] at mapPartitions at RandomForest.scala:521), which has no missing parents
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 42.0 KB, free 412.8 MB)
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 18.8 KB, free 412.8 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.17.0.4:37608 (size: 18.8 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[31] at mapPartitions at RandomForest.scala:521)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 172.17.0.4:37608 in memory (size: 3.6 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5986 bytes)
17/03/26 20:38:06 INFO executor.Executor: Running task 0.0 in stage 9.0 (TID 9)
17/03/26 20:38:06 INFO storage.BlockManager: Found block rdd_27_0 locally
17/03/26 20:38:06 INFO executor.Executor: Finished task 0.0 in stage 9.0 (TID 9). 2218 bytes result sent to driver
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 87 ms on localhost (1/1)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/03/26 20:38:06 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (mapPartitions at RandomForest.scala:521) finished in 0.083 s
17/03/26 20:38:06 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/03/26 20:38:06 INFO scheduler.DAGScheduler: running: Set()
17/03/26 20:38:06 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 10)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: failed: Set()
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[33] at map at RandomForest.scala:540), which has no missing parents
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 11.8 KB, free 412.8 MB)
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.4 KB, free 412.8 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.17.0.4:37608 (size: 5.4 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[33] at map at RandomForest.scala:540)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, ANY, 5249 bytes)
17/03/26 20:38:06 INFO executor.Executor: Running task 0.0 in stage 10.0 (TID 10)
17/03/26 20:38:06 INFO storage.ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/26 20:38:06 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/26 20:38:06 INFO executor.Executor: Finished task 0.0 in stage 10.0 (TID 10). 9278 bytes result sent to driver
17/03/26 20:38:06 INFO scheduler.DAGScheduler: ResultStage 10 (collectAsMap at RandomForest.scala:550) finished in 0.036 s
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Job 7 finished: collectAsMap at RandomForest.scala:550, took 0.161133 s
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 48 ms on localhost (1/1)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 9.7 KB, free 412.8 MB)
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 1185.0 B, free 412.8 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.17.0.4:37608 (size: 1185.0 B, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.SparkContext: Created broadcast 17 from broadcast at RandomForest.scala:500
17/03/26 20:38:06 INFO spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:550
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Registering RDD 34 (mapPartitions at RandomForest.scala:521)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Got job 8 (collectAsMap at RandomForest.scala:550) with 1 output partitions
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Final stage: ResultStage 12 (collectAsMap at RandomForest.scala:550)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[34] at mapPartitions at RandomForest.scala:521), which has no missing parents
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 53.3 KB, free 412.7 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 172.17.0.4:37608 in memory (size: 774.0 B, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.ContextCleaner: Cleaned shuffle 2
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 172.17.0.4:37608 in memory (size: 18.8 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 172.17.0.4:37608 in memory (size: 5.4 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.7 KB, free 412.8 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.17.0.4:37608 (size: 23.7 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[34] at mapPartitions at RandomForest.scala:521)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5986 bytes)
17/03/26 20:38:06 INFO executor.Executor: Running task 0.0 in stage 11.0 (TID 11)
17/03/26 20:38:06 INFO storage.BlockManager: Found block rdd_27_0 locally
17/03/26 20:38:06 INFO executor.Executor: Finished task 0.0 in stage 11.0 (TID 11). 2131 bytes result sent to driver
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 69 ms on localhost (1/1)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/03/26 20:38:06 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (mapPartitions at RandomForest.scala:521) finished in 0.063 s
17/03/26 20:38:06 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/03/26 20:38:06 INFO scheduler.DAGScheduler: running: Set()
17/03/26 20:38:06 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 12)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: failed: Set()
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[36] at map at RandomForest.scala:540), which has no missing parents
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 15.4 KB, free 412.7 MB)
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.9 KB, free 412.7 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.17.0.4:37608 (size: 6.9 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[36] at map at RandomForest.scala:540)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0, ANY, 5249 bytes)
17/03/26 20:38:06 INFO executor.Executor: Running task 0.0 in stage 12.0 (TID 12)
17/03/26 20:38:06 INFO storage.ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/26 20:38:06 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/26 20:38:06 INFO executor.Executor: Finished task 0.0 in stage 12.0 (TID 12). 16486 bytes result sent to driver
17/03/26 20:38:06 INFO scheduler.DAGScheduler: ResultStage 12 (collectAsMap at RandomForest.scala:550) finished in 0.027 s
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Job 8 finished: collectAsMap at RandomForest.scala:550, took 0.152185 s
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 18.8 KB, free 412.7 MB)
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 37 ms on localhost (1/1)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 172.17.0.4:37608 in memory (size: 6.9 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 172.17.0.4:37608 in memory (size: 1185.0 B, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.ContextCleaner: Cleaned shuffle 3
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 172.17.0.4:37608 in memory (size: 23.7 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.1 KB, free 412.8 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.17.0.4:37608 (size: 2.1 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.SparkContext: Created broadcast 20 from broadcast at RandomForest.scala:500
17/03/26 20:38:06 INFO spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:550
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Registering RDD 37 (mapPartitions at RandomForest.scala:521)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Got job 9 (collectAsMap at RandomForest.scala:550) with 1 output partitions
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (collectAsMap at RandomForest.scala:550)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[37] at mapPartitions at RandomForest.scala:521), which has no missing parents
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 75.3 KB, free 412.8 MB)
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 33.5 KB, free 412.7 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.17.0.4:37608 (size: 33.5 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[37] at mapPartitions at RandomForest.scala:521)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5986 bytes)
17/03/26 20:38:06 INFO executor.Executor: Running task 0.0 in stage 13.0 (TID 13)
17/03/26 20:38:06 INFO storage.BlockManager: Found block rdd_27_0 locally
17/03/26 20:38:06 INFO executor.Executor: Finished task 0.0 in stage 13.0 (TID 13). 2131 bytes result sent to driver
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 101 ms on localhost (1/1)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/03/26 20:38:06 INFO scheduler.DAGScheduler: ShuffleMapStage 13 (mapPartitions at RandomForest.scala:521) finished in 0.096 s
17/03/26 20:38:06 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/03/26 20:38:06 INFO scheduler.DAGScheduler: running: Set()
17/03/26 20:38:06 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 14)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: failed: Set()
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[39] at map at RandomForest.scala:540), which has no missing parents
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 22.4 KB, free 412.7 MB)
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.8 KB, free 412.7 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.17.0.4:37608 (size: 9.8 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[39] at map at RandomForest.scala:540)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0, ANY, 5249 bytes)
17/03/26 20:38:06 INFO executor.Executor: Running task 0.0 in stage 14.0 (TID 14)
17/03/26 20:38:06 INFO storage.ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/26 20:38:06 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/26 20:38:06 INFO executor.Executor: Finished task 0.0 in stage 14.0 (TID 14). 30425 bytes result sent to driver
17/03/26 20:38:06 INFO scheduler.DAGScheduler: ResultStage 14 (collectAsMap at RandomForest.scala:550) finished in 0.095 s
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Job 9 finished: collectAsMap at RandomForest.scala:550, took 0.244361 s
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 103 ms on localhost (1/1)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 36.1 KB, free 412.7 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on 172.17.0.4:37608 in memory (size: 9.8 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on 172.17.0.4:37608 in memory (size: 2.1 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.ContextCleaner: Cleaned shuffle 4
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on 172.17.0.4:37608 in memory (size: 33.5 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.8 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.17.0.4:37608 (size: 3.7 KB, free: 413.2 MB)
17/03/26 20:38:06 INFO spark.SparkContext: Created broadcast 23 from broadcast at RandomForest.scala:500
17/03/26 20:38:06 INFO spark.SparkContext: Starting job: collectAsMap at RandomForest.scala:550
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Registering RDD 40 (mapPartitions at RandomForest.scala:521)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Got job 10 (collectAsMap at RandomForest.scala:550) with 1 output partitions
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Final stage: ResultStage 16 (collectAsMap at RandomForest.scala:550)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 15)
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[40] at mapPartitions at RandomForest.scala:521), which has no missing parents
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 118.8 KB, free 412.7 MB)
17/03/26 20:38:06 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 52.5 KB, free 412.6 MB)
17/03/26 20:38:06 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.17.0.4:37608 (size: 52.5 KB, free: 413.1 MB)
17/03/26 20:38:06 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[40] at mapPartitions at RandomForest.scala:521)
17/03/26 20:38:06 INFO scheduler.TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/03/26 20:38:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0, PROCESS_LOCAL, 5986 bytes)
17/03/26 20:38:06 INFO executor.Executor: Running task 0.0 in stage 15.0 (TID 15)
17/03/26 20:38:06 INFO storage.BlockManager: Found block rdd_27_0 locally
17/03/26 20:38:07 INFO executor.Executor: Finished task 0.0 in stage 15.0 (TID 15). 2204 bytes result sent to driver
17/03/26 20:38:07 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 158 ms on localhost (1/1)
17/03/26 20:38:07 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/03/26 20:38:07 INFO scheduler.DAGScheduler: ShuffleMapStage 15 (mapPartitions at RandomForest.scala:521) finished in 0.153 s
17/03/26 20:38:07 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/03/26 20:38:07 INFO scheduler.DAGScheduler: running: Set()
17/03/26 20:38:07 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 16)
17/03/26 20:38:07 INFO scheduler.DAGScheduler: failed: Set()
17/03/26 20:38:07 INFO scheduler.DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[42] at map at RandomForest.scala:540), which has no missing parents
17/03/26 20:38:07 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 35.8 KB, free 412.6 MB)
17/03/26 20:38:07 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 15.3 KB, free 412.6 MB)
17/03/26 20:38:07 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.17.0.4:37608 (size: 15.3 KB, free: 413.1 MB)
17/03/26 20:38:07 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:07 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[42] at map at RandomForest.scala:540)
17/03/26 20:38:07 INFO scheduler.TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/03/26 20:38:07 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, partition 0, ANY, 5249 bytes)
17/03/26 20:38:07 INFO executor.Executor: Running task 0.0 in stage 16.0 (TID 16)
17/03/26 20:38:07 INFO storage.ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/26 20:38:07 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/26 20:38:07 INFO executor.Executor: Finished task 0.0 in stage 16.0 (TID 16). 55680 bytes result sent to driver
17/03/26 20:38:07 INFO scheduler.DAGScheduler: ResultStage 16 (collectAsMap at RandomForest.scala:550) finished in 0.122 s
17/03/26 20:38:07 INFO scheduler.DAGScheduler: Job 10 finished: collectAsMap at RandomForest.scala:550, took 0.330858 s
17/03/26 20:38:07 INFO rdd.MapPartitionsRDD: Removing RDD 27 from persistence list
17/03/26 20:38:07 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 131 ms on localhost (1/1)
17/03/26 20:38:07 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/03/26 20:38:07 INFO storage.BlockManager: Removing RDD 27
17/03/26 20:38:07 INFO impl.RandomForest: Internal timing for DecisionTree:
17/03/26 20:38:07 INFO impl.RandomForest:   init: 3.208797564
  total: 5.153859656
  findSplits: 2.310215502
  findBestSplits: 1.893653615
  chooseSplits: 1.88475092
17/03/26 20:38:07 INFO spark.SparkContext: Starting job: first at RandomForestRegressor.scala:108
17/03/26 20:38:07 INFO scheduler.DAGScheduler: Got job 11 (first at RandomForestRegressor.scala:108) with 1 output partitions
17/03/26 20:38:07 INFO scheduler.DAGScheduler: Final stage: ResultStage 17 (first at RandomForestRegressor.scala:108)
17/03/26 20:38:07 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/03/26 20:38:07 INFO scheduler.DAGScheduler: Missing parents: List()
17/03/26 20:38:07 INFO scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[19] at map at Predictor.scala:124), which has no missing parents
17/03/26 20:38:07 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 25.5 KB, free 413.2 MB)
17/03/26 20:38:07 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 11.0 KB, free 413.2 MB)
17/03/26 20:38:07 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.17.0.4:37608 (size: 11.0 KB, free: 413.8 MB)
17/03/26 20:38:07 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:07 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[19] at map at Predictor.scala:124)
17/03/26 20:38:07 INFO scheduler.TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/03/26 20:38:07 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, partition 0, PROCESS_LOCAL, 5991 bytes)
17/03/26 20:38:07 INFO executor.Executor: Running task 0.0 in stage 17.0 (TID 17)
17/03/26 20:38:07 INFO datasources.FileScanRDD: Reading File path: file:///regtool/static/data/delta_error.libsvm, range: 0-174636, partition values: [empty row]
17/03/26 20:38:07 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on 172.17.0.4:37608 in memory (size: 15.3 KB, free: 413.8 MB)
17/03/26 20:38:07 INFO executor.Executor: Finished task 0.0 in stage 17.0 (TID 17). 2180 bytes result sent to driver
17/03/26 20:38:07 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 92 ms on localhost (1/1)
17/03/26 20:38:07 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/03/26 20:38:07 INFO scheduler.DAGScheduler: ResultStage 17 (first at RandomForestRegressor.scala:108) finished in 0.073 s
17/03/26 20:38:07 INFO scheduler.DAGScheduler: Job 11 finished: first at RandomForestRegressor.scala:108, took 0.110510 s
17/03/26 20:38:07 INFO util.Instrumentation: RandomForestRegressor-RandomForestRegressor_46d39ead464f96cb904c-550524158-1: training finished
17/03/26 20:38:07 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on 172.17.0.4:37608 in memory (size: 11.0 KB, free: 413.8 MB)
17/03/26 20:38:07 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 304.2 KB, free 413.0 MB)
17/03/26 20:38:07 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 72.4 KB, free 412.9 MB)
17/03/26 20:38:07 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.17.0.4:37608 (size: 72.4 KB, free: 413.7 MB)
17/03/26 20:38:07 INFO spark.SparkContext: Created broadcast 27 from broadcast at RandomForestRegressor.scala:170
17/03/26 20:38:08 INFO datasources.FileSourceStrategy: Pruning directories with: 
17/03/26 20:38:08 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
17/03/26 20:38:08 INFO datasources.FileSourceStrategy: Pruned Data Schema: struct<label: double, features: vector>
17/03/26 20:38:08 INFO datasources.FileSourceStrategy: Pushed Filters: 
17/03/26 20:38:08 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 264.4 KB, free 412.7 MB)
17/03/26 20:38:08 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 23.1 KB, free 412.7 MB)
17/03/26 20:38:08 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.17.0.4:37608 (size: 23.1 KB, free: 413.7 MB)
17/03/26 20:38:08 INFO spark.SparkContext: Created broadcast 28 from broadcast at LibSVMRelation.scala:161
17/03/26 20:38:08 INFO datasources.FileSourceStrategy: Planning scan with bin packing, max size: 4368940 bytes, open cost is considered as scanning 4194304 bytes.
17/03/26 20:38:08 INFO codegen.CodeGenerator: Code generated in 69.474596 ms
17/03/26 20:38:08 INFO spark.SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/03/26 20:38:08 INFO scheduler.DAGScheduler: Got job 12 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/03/26 20:38:08 INFO scheduler.DAGScheduler: Final stage: ResultStage 18 (aggregate at RegressionMetrics.scala:57)
17/03/26 20:38:08 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/03/26 20:38:08 INFO scheduler.DAGScheduler: Missing parents: List()
17/03/26 20:38:08 INFO scheduler.DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:55), which has no missing parents
17/03/26 20:38:08 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 23.7 KB, free 412.6 MB)
17/03/26 20:38:08 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 10.6 KB, free 412.6 MB)
17/03/26 20:38:08 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.17.0.4:37608 (size: 10.6 KB, free: 413.7 MB)
17/03/26 20:38:08 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:08 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[48] at map at RegressionMetrics.scala:55)
17/03/26 20:38:08 INFO scheduler.TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/03/26 20:38:08 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, partition 0, PROCESS_LOCAL, 5995 bytes)
17/03/26 20:38:08 INFO executor.Executor: Running task 0.0 in stage 18.0 (TID 18)
17/03/26 20:38:08 INFO codegen.CodeGenerator: Code generated in 25.139619 ms
17/03/26 20:38:08 INFO datasources.FileScanRDD: Reading File path: file:///regtool/static/data/delta_error.libsvm, range: 0-174636, partition values: [empty row]
17/03/26 20:38:08 INFO executor.Executor: Finished task 0.0 in stage 18.0 (TID 18). 2180 bytes result sent to driver
17/03/26 20:38:08 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 220 ms on localhost (1/1)
17/03/26 20:38:08 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/03/26 20:38:08 INFO scheduler.DAGScheduler: ResultStage 18 (aggregate at RegressionMetrics.scala:57) finished in 0.215 s
17/03/26 20:38:08 INFO scheduler.DAGScheduler: Job 12 finished: aggregate at RegressionMetrics.scala:57, took 0.234665 s
17/03/26 20:38:08 INFO memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 304.1 KB, free 412.3 MB)
17/03/26 20:38:08 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on 172.17.0.4:37608 in memory (size: 10.6 KB, free: 413.7 MB)
17/03/26 20:38:08 INFO memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 72.4 KB, free 412.3 MB)
17/03/26 20:38:08 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.17.0.4:37608 (size: 72.4 KB, free: 413.6 MB)
17/03/26 20:38:08 INFO spark.SparkContext: Created broadcast 30 from broadcast at RandomForestRegressor.scala:170
17/03/26 20:38:09 INFO datasources.FileSourceStrategy: Pruning directories with: 
17/03/26 20:38:09 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
17/03/26 20:38:09 INFO datasources.FileSourceStrategy: Pruned Data Schema: struct<label: double, features: vector>
17/03/26 20:38:09 INFO datasources.FileSourceStrategy: Pushed Filters: 
17/03/26 20:38:09 INFO memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 264.4 KB, free 412.0 MB)
17/03/26 20:38:09 INFO memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 23.1 KB, free 412.0 MB)
17/03/26 20:38:09 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.17.0.4:37608 (size: 23.1 KB, free: 413.6 MB)
17/03/26 20:38:09 INFO spark.SparkContext: Created broadcast 31 from toPandas at /regtool/ml_moduel/random_forest_regression.py:51
17/03/26 20:38:09 INFO datasources.FileSourceStrategy: Planning scan with bin packing, max size: 4368940 bytes, open cost is considered as scanning 4194304 bytes.
17/03/26 20:38:09 INFO codegen.CodeGenerator: Code generated in 87.456327 ms
17/03/26 20:38:09 INFO spark.SparkContext: Starting job: toPandas at /regtool/ml_moduel/random_forest_regression.py:51
17/03/26 20:38:09 INFO scheduler.DAGScheduler: Got job 13 (toPandas at /regtool/ml_moduel/random_forest_regression.py:51) with 1 output partitions
17/03/26 20:38:09 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (toPandas at /regtool/ml_moduel/random_forest_regression.py:51)
17/03/26 20:38:09 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/03/26 20:38:09 INFO scheduler.DAGScheduler: Missing parents: List()
17/03/26 20:38:09 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[51] at toPandas at /regtool/ml_moduel/random_forest_regression.py:51), which has no missing parents
17/03/26 20:38:09 INFO memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 25.7 KB, free 412.0 MB)
17/03/26 20:38:09 INFO memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 9.6 KB, free 412.0 MB)
17/03/26 20:38:09 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.17.0.4:37608 (size: 9.6 KB, free: 413.6 MB)
17/03/26 20:38:09 INFO spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1012
17/03/26 20:38:09 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[51] at toPandas at /regtool/ml_moduel/random_forest_regression.py:51)
17/03/26 20:38:09 INFO scheduler.TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/03/26 20:38:09 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, partition 0, PROCESS_LOCAL, 6103 bytes)
17/03/26 20:38:09 INFO executor.Executor: Running task 0.0 in stage 19.0 (TID 19)
17/03/26 20:38:09 INFO datasources.FileScanRDD: Reading File path: file:///regtool/static/data/delta_error.libsvm, range: 0-174636, partition values: [empty row]
17/03/26 20:38:09 INFO executor.Executor: Finished task 0.0 in stage 19.0 (TID 19). 186631 bytes result sent to driver
17/03/26 20:38:09 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 234 ms on localhost (1/1)
17/03/26 20:38:09 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/03/26 20:38:09 INFO scheduler.DAGScheduler: ResultStage 19 (toPandas at /regtool/ml_moduel/random_forest_regression.py:51) finished in 0.233 s
17/03/26 20:38:09 INFO scheduler.DAGScheduler: Job 13 finished: toPandas at /regtool/ml_moduel/random_forest_regression.py:51, took 0.257020 s
17/03/26 20:38:10 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on 172.17.0.4:37608 in memory (size: 9.6 KB, free: 413.6 MB)
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned accumulator 808
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned accumulator 807
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned accumulator 806
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned accumulator 805
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned accumulator 804
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned accumulator 803
17/03/26 20:38:10 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 172.17.0.4:37608 in memory (size: 23.1 KB, free: 413.6 MB)
17/03/26 20:38:10 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on 172.17.0.4:37608 in memory (size: 72.4 KB, free: 413.7 MB)
17/03/26 20:38:10 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on 172.17.0.4:37608 in memory (size: 52.5 KB, free: 413.8 MB)
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned shuffle 5
17/03/26 20:38:10 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on 172.17.0.4:37608 in memory (size: 3.7 KB, free: 413.8 MB)
17/03/26 20:38:10 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 172.17.0.4:37608 in memory (size: 15.6 KB, free: 413.8 MB)
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned shuffle 1
17/03/26 20:38:10 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 172.17.0.4:37608 in memory (size: 525.0 B, free: 413.8 MB)
17/03/26 20:38:10 INFO storage.BlockManager: Removing RDD 27
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned RDD 27
17/03/26 20:38:10 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 172.17.0.4:37608 in memory (size: 13.7 KB, free: 413.8 MB)
17/03/26 20:38:10 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 172.17.0.4:37608 in memory (size: 12.5 KB, free: 413.8 MB)
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned shuffle 0
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned accumulator 142
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned accumulator 141
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned accumulator 140
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned accumulator 139
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned accumulator 138
17/03/26 20:38:10 INFO spark.ContextCleaner: Cleaned accumulator 137
17/03/26 20:38:10 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 172.17.0.4:37608 in memory (size: 23.1 KB, free: 413.8 MB)
17/03/26 20:38:11 INFO spark.SparkContext: Invoking stop() from shutdown hook
17/03/26 20:38:11 INFO server.ServerConnector: Stopped ServerConnector@1bb4504c{HTTP/1.1}{0.0.0.0:4040}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@5650d913{/stages/stage/kill,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@38a383f3{/api,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@22b7b11b{/,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@533d555{/static,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@d9c6034{/executors/threadDump/json,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@4a4a0886{/executors/threadDump,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@525eafbf{/executors/json,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@44f98bd1{/executors,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@6e55288b{/environment/json,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@9c239d3{/environment,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@615eedfc{/storage/rdd/json,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@11476838{/storage/rdd,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@40f4e080{/storage/json,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@43956c28{/storage,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@1f9dee92{/stages/pool/json,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@7774d2d4{/stages/pool,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@1fd3962c{/stages/stage/json,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@397cb51c{/stages/stage,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@3dd7b8b{/stages/json,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@328b489a{/stages,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@23e0bd32{/jobs/job/json,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@e769db9{/jobs/job,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@f77c212{/jobs/json,null,UNAVAILABLE}
17/03/26 20:38:11 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@32e463cf{/jobs,null,UNAVAILABLE}
17/03/26 20:38:11 INFO ui.SparkUI: Stopped Spark web UI at http://172.17.0.4:4040
17/03/26 20:38:11 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/26 20:38:11 INFO memory.MemoryStore: MemoryStore cleared
17/03/26 20:38:11 INFO storage.BlockManager: BlockManager stopped
17/03/26 20:38:11 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
17/03/26 20:38:11 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/26 20:38:11 INFO spark.SparkContext: Successfully stopped SparkContext
17/03/26 20:38:11 INFO util.ShutdownHookManager: Shutdown hook called
17/03/26 20:38:11 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-ac333ad8-13b2-4152-9034-97a87dd4b7f8
17/03/26 20:38:11 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-ac333ad8-13b2-4152-9034-97a87dd4b7f8/pyspark-b185319b-74e1-4110-9eec-83a9025ba4cc
